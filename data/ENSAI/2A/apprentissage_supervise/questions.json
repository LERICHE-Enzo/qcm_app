{
  "questions": [
    {
      "id": "2022-q001",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "Parmi les problématiques ci-dessous, laquelle ou lesquelles ne relèvent pas de l’apprentissage supervisé ?",
      "choices": [
        "Identifier des vidéos similaires parmi tout le catalogue d’un site de streaming.",
        "Construire un algorithme de recommandation de séries pour les abonnés d’un site de streaming.",
        "Estimer le nombre de vues des vidéos d’un type particulier dans le catalogue d’un site de streaming.",
        "Filtrer les commentaires postés sur des vidéos qui ne respectent pas les conditions d’utilisation du site de streaming."
      ],
      "answer": [
        0,
        2
      ],
      "explanation": "L’identification de vidéos similaires (a) relève de l’apprentissage non supervisé (clustering, recherche de similarité). L’estimation du nombre de vues (c) correspond davantage à une tâche de modélisation descriptive ou prédictive, sans supervision explicite. En revanche, la recommandation (b) et le filtrage de commentaires (d) s’appuient sur des étiquettes (notes, exemples positifs/négatifs), et relèvent donc de l’apprentissage supervisé.",
      "tags": [
        "Partiel-2022",
        "apprentissage supervisé",
        "apprentissage non supervisé",
        "recommandation",
        "classification"
      ]
    },
    {
      "id": "2022-q002",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "Parmi ces fonctions de coût pour l’apprentissage supervisé, laquelle ou lesquelles sont adaptées (au regard des propriétés théoriques d’une fonction de coût) ?",
      "choices": [
        "$\\ell(y,y')=(y-y')^{3}$ si $y,y'\\in\\mathbb{R}$",
        "$\\ell(y,y')=2\\,\\mathbf{1}\\{y\\neq y'\\}$ si $y,y'\\in\\{0,1\\}$",
        "$\\ell(y,y')=-y\\log(y')-(1-y)\\log(1-y')$ si $y,y'\\in\\{0,1\\}$",
        "$\\ell(y,y')=(2y-y')^{2}$ si $y,y'\\in\\mathbb{R}$"
      ],
      "answer": [
        1,
        2
      ],
      "explanation": "(a) n’est pas adaptée : la perte cubique peut être négative et n’est pas convexe. (b) est une perte 0–1 (multipliée par 2) : elle est valide pour la classification même si elle n’est pas convexe ni différentiable. (c) est l’entropie croisée binaire, perte standard et « propre » pour la classification binaire. (d) est mal spécifiée : la perte est nulle quand $y'=2y$ et non quand $y'=y$ ; elle ne cible donc pas correctement la variable à prédire.",
      "tags": [
        "perte",
        "classification",
        "régression",
        "entropie croisée",
        "0-1 loss"
      ]
    },
    {
      "id": "2022-q003",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "Avec lequel ou lesquels de ces échantillons peut-on estimer les hyperparamètres d’un modèle d’apprentissage supervisé ?",
      "choices": [
        "L’échantillon d’apprentissage sans procédure particulière.",
        "L’échantillon de test.",
        "L’échantillon de validation dans le cas d’une procédure de validation simple.",
        "L’échantillon d’apprentissage avec procédure de validation croisée."
      ],
      "answer": [
        2,
        3
      ],
      "explanation": "Les hyperparamètres sont ajustés à partir d’un ensemble de validation (procédure simple) ou via validation croisée sur l’échantillon d’apprentissage. L’échantillon de test ne doit pas être utilisé pour ce réglage, car il sert uniquement à évaluer la performance finale du modèle.",
      "tags": [
        "hyperparamètres",
        "validation",
        "cross-validation",
        "échantillons"
      ]
    },
    {
      "id": "2022-q004",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "On a simulé un échantillon de taille $n=1000$ selon le modèle : pour $i=1,\\dots,1000$, $X_i^1 \\sim \\mathcal{N}(0,1)$, $X_i^2 \\sim \\mathcal{N}(1,1)$ avec $X_i^1$ et $X_i^2$ indépendants, $U_i^1 \\sim \\mathcal{U}(0,1)$, $U_i^2 \\sim \\mathcal{U}(10,15)$ et $Y_i = \\text{Voir photo}$. \n\nSeules les variables $X_i^1$ et $X_i^2$ sont considérées comme variables explicatives. À quoi est égal le risque de Bayes ?",
      "image": "/Images/apprentissage_supervise/as-2022-q004.png",
      "choices": [
        "2/10",
        "5/10",
        "7/10",
        "3/10"
      ],
      "answer": [
        3
      ],
      "explanation": "Le risque de Bayes correspond au taux d’erreur minimal théorique atteignable en utilisant la règle de Bayes. Ici, après analyse des probabilités conditionnelles, ce risque vaut $3/10$.",
      "tags": [
        "risque de Bayes",
        "classification",
        "probabilités"
      ]
    },
    {
      "id": "2022-q005",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "On cherche à prédire la valeur d’une variable quantitative $Y$ en fonction de deux variables explicatives, la première quantitative $X_1$ et la seconde qualitative non ordonnée $X_2$, à partir de l’échantillon d’apprentissage suivant. On utilise l’algorithme des plus proches voisins, avec une distance entre deux individus $i$ et $j$ définie par $$d(individu_i, individu_j) = |X_i^1 - X_j^1| + 0.5 \\cdot 1(X_i^2 \\neq X_j^2).$$ Quelle est la valeur prédite pour un nouvel individu $i$ tel que $X_i^1 = 3.5$ et $X_i^2 = \\text{rouge}$ en utilisant un nombre $k=1$ de plus proches voisins ?",
      "image": "/Images/apprentissage_supervise/as-2022-q005.png",
      "choices": [
        "2.5",
        "1.5",
        "1.1",
        "3.7"
      ],
      "answer": [
        1
      ],
      "explanation": "On calcule les distances entre le nouvel individu $(3.5, rouge)$ et les points de l’échantillon. Le plus proche voisin est $(3, vert)$ avec $Y=1.5$ (distance $|3.5-3|+0.5=1$), plus faible que toutes les autres. Donc la valeur prédite est $1.5$.",
      "tags": [
        "k-plus-proches-voisins",
        "distance",
        "régression",
        "apprentissage supervisé"
      ],
      "id_gen": [
        "fixed5_2025-10-06_095822_001"
      ]
    },
    {
      "id": "2022-q006",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "On cherche à prédire la valeur d’une variable quantitative $Y$ en fonction de deux variables explicatives, la première quantitative $X_1$ et la seconde qualitative non ordonnée $X_2$, à partir de l’échantillon d’apprentissage suivant. On utilise l’algorithme des plus proches voisins, avec une distance entre deux individus $i$ et $j$ définie par $$d(individu_i, individu_j) = |X_i^1 - X_j^1| + 0.5 \\cdot 1(X_i^2 \\neq X_j^2).$$ Quelle est la valeur prédite pour un nouvel individu $i$ tel que $X_i^1 = 3.5$ et $X_i^2 = \\text{rouge}$ en utilisant un nombre $k=3$ de plus proches voisins ?",
      "image": "/Images/apprentissage_supervise/as-2022-q005.png",
      "choices": [
        "1.7",
        "2.2",
        "3",
        "2.6"
      ],
      "answer": [
        0
      ],
      "explanation": "On calcule les distances entre le nouvel individu $(3.5, rouge)$ et les points de l’échantillon. Les trois plus proches voisins sont ceux associés aux valeurs $Y=1.5$, $2.5$ et $1.1$. La prédiction est leur moyenne : $(1.5 + 2.5 + 1.1)/3 = 1.7$.",
      "tags": [
        "k-plus-proches-voisins",
        "distance",
        "régression",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2022-q007",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "Pour trouver le nombre optimal de plus proches voisins sur ce problème, on a utilisé une fonction similaire à `tune.control` de la librairie `e1071` en R (utilisée dans le TP1) et on a obtenu le résultat ci-dessous. À quoi correspond l’axe des ordonnées ?",
      "image": "/Images/apprentissage_supervise/as-2022-q007.png",
      "choices": [
        "L’erreur quadratique moyenne (MSE) sur l’échantillon d’apprentissage.",
        "L’erreur quadratique moyenne (MSE) en validation croisée.",
        "Le taux de mal classés sur l’échantillon d’apprentissage.",
        "Le taux de mal classés en validation croisée."
      ],
      "answer": [
        1
      ],
      "explanation": "Le graphique représente l’évolution de l’erreur quadratique moyenne estimée par validation croisée en fonction du nombre de voisins $k$. C’est ce critère qui est utilisé pour choisir le $k$ optimal afin d’éviter le surapprentissage.",
      "tags": [
        "k-plus-proches-voisins",
        "validation croisée",
        "MSE",
        "sélection d’hyperparamètres"
      ]
    },
    {
      "id": "2022-q008",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "Dans lequel ou lesquels des cas de types de variables peut-on utiliser l’analyse discriminante ?",
      "choices": [
        "Variables explicatives et variable à expliquer quantitatives.",
        "Variables explicatives quantitatives et variable à expliquer qualitative.",
        "Variables explicatives qualitatives et quantitatives et variable à expliquer qualitative.",
        "Variables explicatives qualitatives et variable à expliquer qualitative."
      ],
      "answer": [
        1,
        2,
        3
      ],
      "explanation": "L’analyse discriminante s’applique lorsque la variable à expliquer (variable cible) est qualitative. Elle est conçue pour traiter des variables explicatives quantitatives (cas classique), mais peut être adaptée à des mélanges qualitatif/quantitatif via des méthodes généralisées.",
      "tags": [
        "analyse discriminante",
        "classification",
        "variables explicatives"
      ]
    },
    {
      "id": "2022-q009",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "Pour un problème d’apprentissage supervisé avec une variable à expliquer $Y$ qualitative pouvant prendre trois valeurs possibles et deux variables explicatives quantitatives $X_1$ et $X_2$, on a l’échantillon d’apprentissage ci-dessous, où $g_i$ pour $i=1,\\dots,3$ est le barycentre des variables explicatives pour la i-ème catégorie de $Y$ et $g$ est le barycentre de tous les points. Quel serait l’axe discriminant construit par une analyse discriminante linéaire ?",
      "image": "/Images/apprentissage_supervise/as-2022-q009.png",
      "choices": [
        "(a)",
        "(b)",
        "(c)",
        "(d)"
      ],
      "answer": [
        3
      ],
      "explanation": "L’axe discriminant est celui qui maximise la séparation entre les classes tout en passant par le barycentre global $g$. Ici, il correspond à l’axe (d).",
      "tags": [
        "analyse discriminante",
        "classification",
        "axe discriminant",
        "visualisation"
      ]
    },
    {
      "id": "2022-q010",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "Pour un problème d’apprentissage supervisé avec une variable à expliquer $Y$ qualitative pouvant prendre trois valeurs possibles et deux variables explicatives quantitatives $X_1$ et $X_2$, on a l’échantillon d’apprentissage ci-dessous, où $g_i$ pour $i=1,\\dots,3$ est le barycentre des variables explicatives pour la i-ème catégorie de $Y$ et $g$ est le barycentre de tous les points. \n\nDans ce cas, en utilisant laquelle ou lesquelles des méthodes ci-dessous recommanderiez-vous de choisir la règle de décision ?",
      "image": "/Images/apprentissage_supervise/as-2022-q009.png",
      "choices": [
        "Analyse discriminante linéaire.",
        "Analyse discriminante quadratique.",
        "Analyse discriminante bayésienne.",
        "Analyse discriminante linéaire avec ACM au préalable."
      ],
      "answer": [
        1,
        2
      ],
      "explanation": "Dans ce contexte avec trois classes et des distributions qui ne sont pas séparées par des frontières linéaires, l’analyse discriminante quadratique ou bayésienne est plus adaptée qu’une simple analyse discriminante linéaire.",
      "tags": [
        "analyse discriminante",
        "quadratique",
        "bayésienne",
        "classification"
      ]
    },
    {
      "id": "2022-q011",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "Quelle est ou quelles sont les hypothèses faites pour construire le classifieur bayésien naïf ?",
      "choices": [
        "La formule de Bayes.",
        "L’hypothèse d’indépendance des variables explicatives conditionnellement aux modalités prises par la variable à expliquer.",
        "La formule des probabilités totales.",
        "Les variables explicatives suivent une loi normale multivariée."
      ],
      "answer": [
        1
      ],
      "explanation": "Le classifieur bayésien naïf repose sur l’hypothèse d’indépendance conditionnelle des variables explicatives sachant la variable cible. La formule de Bayes est un outil utilisé, mais ce n’est pas une hypothèse. L’hypothèse de normalité multivariée est celle de l’analyse discriminante, pas du naïf Bayes.",
      "tags": [
        "bayésien naïf",
        "indépendance conditionnelle",
        "classification"
      ]
    },
    {
      "id": "2022-q012",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "Lors du premier TP, vous avez utilisé la validation croisée pour choisir les hyperparamètres d’un classifieur bayésien naïf, avec les résultats ci-dessous. À quoi correspond un choix d’hyperparamètre « FALSE » pour l’utilisation d’un noyau ?",
      "image": "/Images/apprentissage_supervise/as-2022-q012.png",
      "choices": [
        "Une correction de Laplace égale à 1.",
        "Une loi normale pour chaque variable explicative conditionnellement aux modalités de la variable à expliquer.",
        "Une largeur de bande égale à 0.",
        "Autre."
      ],
      "answer": [
        1
      ],
      "explanation": "Lorsque l’option « kernel » est mise à FALSE, le classifieur bayésien naïf suppose que chaque variable explicative numérique suit une loi normale conditionnellement à la classe. Avec TRUE, une estimation par noyau est utilisée à la place.",
      "tags": [
        "bayésien naïf",
        "hyperparamètres",
        "validation croisée",
        "loi normale"
      ]
    },
    {
      "id": "2022-q013",
      "qcm": "Partiel-2022",
      "theme": "Apprentissage supervisé",
      "question": "Lors du premier TP, vous avez utilisé la validation croisée pour choisir les hyperparamètres d’un classifieur bayésien naïf, avec les résultats ci-dessous. Dans ce cas, quel choix d’hyperparamètres recommandez-vous ?",
      "image": "/Images/apprentissage_supervise/as-2022-q012.png",
      "choices": [
        "Estimation gaussienne de la densité des régresseurs avec correction de Laplace égale à 0.",
        "Estimation par noyau de la densité des régresseurs avec largeur de bande égale à 5 et correction de Laplace égale à 5.",
        "Estimation par noyau de la densité des régresseurs avec largeur de bande égale à 5 et correction de Laplace égale à 0.",
        "Estimation par noyau de la densité des régresseurs avec largeur de bande égale à 1 et correction de Laplace égale à 0."
      ],
      "answer": [
        3
      ],
      "explanation": "Selon les résultats de la validation croisée (voir graphique), l’estimation par noyau avec une largeur de bande de 1 et correction de Laplace égale à 0 minimise l’erreur. C’est donc l’hyperparamètre recommandé.",
      "tags": [
        "bayésien naïf",
        "hyperparamètres",
        "validation croisée",
        "Laplace",
        "estimation par noyau"
      ]
    },
    {
      "id": "2023-q001",
      "qcm": "Partiel-2023",
      "theme": "Apprentissage supervisé",
      "question": "Quel est le but de l’apprentissage supervisé en général ?",
      "choices": [
        "Maximiser la complexité du modèle.",
        "Maximiser le risque empirique.",
        "Apprendre à partir de données étiquetées pour faire des prédictions sur de nouvelles données.",
        "Minimiser la taille de l’ensemble de test."
      ],
      "answer": [
        2
      ],
      "explanation": "L’apprentissage supervisé consiste à utiliser des données étiquetées pour apprendre une fonction qui permet de prédire correctement sur de nouvelles données, c’est-à-dire de généraliser.",
      "tags": [
        "objectif",
        "apprentissage supervisé",
        "prédiction",
        "généralisation"
      ],
      "id_gen": [
        "fixed5_2025-10-06_095834_001"
      ]
    },
    {
      "id": "2023-q002",
      "qcm": "Partiel-2023",
      "theme": "Apprentissage supervisé",
      "question": "Qu’est-ce qu’une fonction de perte (ou de risque) en apprentissage supervisé ?",
      "choices": [
        "Une fonction qui mesure la similarité entre deux ensembles de données.",
        "Une fonction qui évalue les performances d’un modèle en comparant ses prédictions aux valeurs réelles.",
        "Une fonction utilisée pour réduire la complexité d’un modèle.",
        "Une fonction qui calcule la probabilité de succès d’un modèle."
      ],
      "answer": [
        1
      ],
      "explanation": "La fonction de perte mesure l’écart entre les prédictions du modèle et les valeurs réelles, ce qui permet d’évaluer et d’optimiser les performances du modèle.",
      "tags": [
        "fonction de perte",
        "risque",
        "performance",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2023-q003",
      "qcm": "Partiel-2023",
      "theme": "Apprentissage supervisé",
      "question": "Quelle fonction de perte (ou de risque) est souvent utilisée pour les problèmes de régression ?",
      "choices": [
        "Entropie croisée.",
        "Erreur quadratique moyenne.",
        "Perte 0-1.",
        "Entropie de Shannon."
      ],
      "answer": [
        1
      ],
      "explanation": "En régression, la fonction de perte la plus courante est l’erreur quadratique moyenne (MSE), qui mesure l’écart quadratique entre les valeurs prédites et observées.",
      "tags": [
        "fonction de perte",
        "régression",
        "MSE",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2023-q004",
      "qcm": "Partiel-2023",
      "theme": "Apprentissage supervisé",
      "question": "Qu’est-ce que le risque empirique en apprentissage supervisé ?",
      "choices": [
        "L’erreur de généralisation du modèle.",
        "L’erreur de prédiction sur l’ensemble d’entraînement.",
        "La complexité du modèle.",
        "La courbe ROC."
      ],
      "answer": [
        1
      ],
      "explanation": "Le risque empirique correspond à l’erreur calculée sur l’échantillon d’apprentissage, c’est-à-dire la moyenne des pertes observées sur les données d’entraînement.",
      "tags": [
        "risque empirique",
        "erreur d’entraînement",
        "apprentissage supervisé"
      ],
      "id_gen": [
        "fixed5_2025-10-06_095822_001"
      ]
    },
    {
      "id": "2023-q005",
      "qcm": "Partiel-2023",
      "theme": "Apprentissage supervisé",
      "question": "Comment fonctionne la méthode des forêts aléatoires ?",
      "choices": [
        "Elle construit un seul arbre de décision.",
        "Elle combine les prédictions de plusieurs arbres pour améliorer la performance.",
        "Elle attribue un poids égal à toutes les caractéristiques.",
        "Elle utilise la méthode du plus proche voisin pour la classification."
      ],
      "answer": [
        1
      ],
      "explanation": "Les forêts aléatoires (random forests) reposent sur la construction de multiples arbres de décision, chacun entraîné sur des échantillons bootstrapés et avec des sous-ensembles de variables aléatoires, puis sur la combinaison de leurs prédictions (vote majoritaire ou moyenne).",
      "tags": [
        "forêts aléatoires",
        "arbres de décision",
        "bagging",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2023-q006",
      "qcm": "Partiel-2023",
      "theme": "Apprentissage supervisé",
      "question": "Qu’est-ce que l’overfitting (surapprentissage) dans le contexte de l’apprentissage supervisé ?",
      "choices": [
        "C’est lorsque le modèle ne parvient pas à apprendre des données.",
        "C’est lorsque le modèle s’adapte trop bien aux données d’entraînement mais ne généralise pas bien.",
        "C’est une condition nécessaire pour un bon modèle.",
        "C’est un synonyme de sous-apprentissage."
      ],
      "answer": [
        1
      ],
      "explanation": "L’overfitting survient quand un modèle apprend trop précisément les données d’entraînement (y compris le bruit), ce qui empêche une bonne généralisation sur de nouvelles données.",
      "tags": [
        "overfitting",
        "surapprentissage",
        "généralisation",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2023-q007",
      "qcm": "Partiel-2023",
      "theme": "Apprentissage supervisé",
      "question": "Qu’est-ce que la matrice de confusion dans le contexte de la classification ?",
      "choices": [
        "Une matrice qui représente la complexité du modèle.",
        "Une matrice qui indique combien de fois le modèle a sous-estimé les valeurs réelles.",
        "Une matrice qui montre les vrais positifs, faux positifs, vrais négatifs et faux négatifs.",
        "Une matrice qui mesure la complexité du modèle."
      ],
      "answer": [
        2
      ],
      "explanation": "La matrice de confusion est un outil d’évaluation des performances d’un modèle de classification. Elle décompose les prédictions en quatre catégories : vrais positifs (VP), faux positifs (FP), vrais négatifs (VN) et faux négatifs (FN).",
      "tags": [
        "matrice de confusion",
        "classification",
        "évaluation",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2023-q008",
      "qcm": "Partiel-2023",
      "theme": "Apprentissage supervisé",
      "question": "Quelle est la principale différence entre la régression et la classification ?",
      "choices": [
        "La régression consiste à prédire des catégories, tandis que la classification consiste à prédire des valeurs continues.",
        "La régression consiste à prédire des valeurs continues, tandis que la classification consiste à prédire des catégories.",
        "La régression est basée sur des arbres de décision, tandis que la classification est basée sur des plus proches voisins.",
        "La régression utilise la validation croisée, tandis que la classification utilise la validation simple."
      ],
      "answer": [
        1
      ],
      "explanation": "La différence fondamentale est que la régression prédit une variable quantitative continue, tandis que la classification prédit une variable qualitative (catégorielle).",
      "tags": [
        "régression",
        "classification",
        "apprentissage supervisé",
        "prédiction"
      ]
    },
    {
      "id": "2023-q009",
      "qcm": "Partiel-2023",
      "theme": "Apprentissage supervisé",
      "question": "Dans la validation croisée à B-blocs, comment les données sont-elles divisées ?",
      "choices": [
        "Les données sont divisées en K sous-ensembles de taille égale, et le modèle est entraîné K fois, en utilisant un sous-ensemble différent comme ensemble de test à chaque itération.",
        "Les données sont divisées en deux ensembles, un pour l’entraînement et un pour la validation.",
        "Les données sont divisées en un sous-ensemble d’entraînement et un sous-ensemble de test à proportions égales.",
        "Les données ne sont pas divisées, mais le modèle est évalué sur plusieurs sous-ensembles de test distincts."
      ],
      "answer": [
        0
      ],
      "explanation": "La validation croisée à K-blocs (ou K-fold cross-validation) consiste à diviser l’échantillon en K sous-ensembles de taille similaire. Le modèle est entraîné K fois, chaque fois sur K-1 blocs et évalué sur le bloc restant, ce qui permet une estimation robuste des performances.",
      "tags": [
        "validation croisée",
        "évaluation modèle",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2023-q010",
      "qcm": "Partiel-2023",
      "theme": "Apprentissage supervisé",
      "question": "Quel rôle joue la validation croisée ?",
      "choices": [
        "Elle aide à choisir le modèle le plus complexe.",
        "Elle permet de tester différents algorithmes d’apprentissage.",
        "Elle évalue la performance du modèle sur différentes valeurs d’hyperparamètres et aide à sélectionner les meilleurs.",
        "Elle ne joue aucun rôle dans l’optimisation des hyperparamètres."
      ],
      "answer": [
        2
      ],
      "explanation": "La validation croisée est utilisée pour estimer la performance d’un modèle et sélectionner les hyperparamètres optimaux, en évitant le surapprentissage et en favorisant la généralisation.",
      "tags": [
        "validation croisée",
        "sélection d’hyperparamètres",
        "évaluation modèle",
        "apprentissage supervisé"
      ],
      "id_gen": [
        "fixed5_2025-10-06_095822_001"
      ]
    },
    {
      "id": "2024-q001",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Quelle est la principale différence entre l’apprentissage supervisé et l’apprentissage non supervisé ?",
      "choices": [
        "L’apprentissage supervisé nécessite des données non étiquetées.",
        "L’apprentissage supervisé utilise des données étiquetées.",
        "L’apprentissage non supervisé prédit des étiquettes pour de nouvelles données.",
        "L’apprentissage supervisé ne peut être utilisé que pour les problèmes de classification."
      ],
      "answer": [
        1
      ],
      "explanation": "La différence fondamentale est que l’apprentissage supervisé repose sur des données étiquetées (paires entrée-sortie), alors que l’apprentissage non supervisé utilise des données non étiquetées pour découvrir des structures ou regroupements.",
      "tags": [
        "apprentissage supervisé",
        "apprentissage non supervisé",
        "étiquettes",
        "classification"
      ]
    },
    {
      "id": "2024-q002",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Quel est un exemple de problème de régression en apprentissage supervisé ?",
      "choices": [
        "Classer les emails en \"spam\" ou \"non-spam\" à partir de leurs caractéristiques.",
        "Segmenter un ensemble de clients en groupes basés sur leurs achats.",
        "Prédire le prix de vente d’une maison à partir de ses caractéristiques.",
        "Identifier la catégorie à laquelle appartient une image."
      ],
      "answer": [
        2
      ],
      "explanation": "Un problème de régression consiste à prédire une variable quantitative continue. Ici, prédire le prix d’une maison correspond à une variable continue, contrairement aux autres exemples qui relèvent de la classification ou du clustering.",
      "tags": [
        "régression",
        "apprentissage supervisé",
        "exemple"
      ],
      "id_gen": [
        "fixed5_2025-10-06_095834_001"
      ]
    },
    {
      "id": "2024-q003",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Qu’est-ce que le risque empirique en apprentissage supervisé ?",
      "choices": [
        "La probabilité qu’un modèle échoue lors de son déploiement en production.",
        "Le coût associé à l’utilisation d’un modèle spécifique pour une tâche de prédiction.",
        "La moyenne des erreurs sur l’ensemble d’entraînement.",
        "La différence entre les erreurs de prédiction sur les ensembles d’entraînement et de test."
      ],
      "answer": [
        2
      ],
      "explanation": "Le risque empirique correspond à la moyenne des erreurs (ou de la fonction de perte) calculée sur l’échantillon d’entraînement. Il mesure l’adéquation du modèle aux données vues pendant l’apprentissage.",
      "tags": [
        "risque empirique",
        "apprentissage supervisé",
        "erreur d’entraînement"
      ]
    },
    {
      "id": "2024-q004",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Quelle est une cause commune du sous-apprentissage ?",
      "choices": [
        "Un modèle trop simple incapable de capturer la complexité des données.",
        "Un trop grand nombre de caractéristiques par rapport aux observations.",
        "Un entraînement excessif du modèle sur les données d’entraînement.",
        "L’utilisation de la régularisation avec un paramètre trop élevé."
      ],
      "answer": [
        0
      ],
      "explanation": "Le sous-apprentissage (underfitting) survient lorsque le modèle est trop simple pour capturer les relations présentes dans les données. Une des causes les plus fréquentes est l’utilisation d’un modèle trop peu complexe.",
      "tags": [
        "sous-apprentissage",
        "underfitting",
        "modèle simple",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2024-q005",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Comment peut-on généralement résoudre le problème de sur-apprentissage ?",
      "choices": [
        "En augmentant le nombre de caractéristiques utilisées par le modèle.",
        "En entraînant le modèle plus longtemps.",
        "En utilisant des techniques de régularisation ou en réduisant la complexité du modèle.",
        "En collectant plus de données d’entraînement."
      ],
      "answer": [
        2
      ],
      "explanation": "Le sur-apprentissage (overfitting) survient lorsque le modèle est trop complexe et s’adapte trop précisément aux données d’entraînement. Pour le résoudre, on utilise des techniques de régularisation (L1, L2, dropout, etc.) ou on réduit la complexité du modèle afin de favoriser la généralisation.",
      "tags": [
        "sur-apprentissage",
        "overfitting",
        "régularisation",
        "complexité du modèle",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2024-q006",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Quelle est une caractéristique de la validation croisée k-fold ?",
      "choices": [
        "Le modèle est entraîné k fois sur le même ensemble d'entraînement.",
        "L'ensemble de données est divisé en k sous-ensembles, et le modèle est entraîné k fois, chaque fois en utilisant un sous-ensemble différent comme ensemble de test.",
        "Elle ne peut être utilisée qu'avec des modèles de régression linéaire.",
        "Elle requiert que les données soient divisées en k sous-ensembles de taille identique, avec un sous-ensemble pour l'entraînement et les k-1 restants pour le test."
      ],
      "answer": [
        1
      ],
      "explanation": "En validation croisée k-fold, les données sont divisées en k parties de taille similaire. Le modèle est entraîné k fois, à chaque fois sur k-1 blocs et évalué sur le bloc restant. Cela permet d'obtenir une estimation robuste de la performance du modèle.",
      "tags": [
        "validation croisée",
        "k-fold",
        "évaluation modèle",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2024-q007",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Quel est un inconvénient de la validation croisée k-fold comparé à l’utilisation d’un simple ensemble de validation ?",
      "choices": [
        "Elle ne permet pas une évaluation précise de la capacité de généralisation du modèle.",
        "Elle peut être plus coûteuse en termes de calcul, car elle nécessite d’entraîner le modèle plusieurs fois.",
        "Elle est moins fiable dans l’évaluation de la performance du modèle.",
        "Elle ne peut être utilisée que pour des tâches de classification."
      ],
      "answer": [
        1
      ],
      "explanation": "L’inconvénient principal de la validation croisée k-fold est son coût computationnel, car le modèle doit être entraîné k fois (autant que le nombre de plis). En revanche, elle fournit une estimation robuste des performances.",
      "tags": [
        "validation croisée",
        "k-fold",
        "inconvénients",
        "apprentissage supervisé"
      ],
      "id_gen": [
        "qcm001_2025-10-06"
      ]
    },
    {
      "id": "2024-q008",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Le k dans k-NN signifie :",
      "choices": [
        "Le nombre de voisins les plus proches à considérer.",
        "Le nombre de classes dans le jeu de données.",
        "Le type de noyau utilisé pour le lissage.",
        "La dimensionnalité des données d’entrée."
      ],
      "answer": [
        0
      ],
      "explanation": "Dans l’algorithme des k plus proches voisins (k-NN), le paramètre k correspond au nombre de voisins à prendre en compte pour prédire la valeur de sortie d’une nouvelle observation.",
      "tags": [
        "k-NN",
        "paramètre k",
        "plus proches voisins",
        "apprentissage supervisé"
      ],
      "id_gen": [
        "qcm001_2025-10-06"
      ]
    },
    {
      "id": "2024-q009",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Quelle est la conséquence d’un k très petit dans l’algorithme k-NN ?",
      "choices": [
        "Risque accru de sous-apprentissage.",
        "Risque accru de sur-apprentissage.",
        "Diminution significative du temps de calcul.",
        "Meilleure généralisation sur les données de test."
      ],
      "answer": [
        1
      ],
      "explanation": "Avec un k très petit, le modèle k-NN devient trop sensible aux points de bruit et aux particularités de l’échantillon d’apprentissage, ce qui conduit à un risque accru de sur-apprentissage (overfitting).",
      "tags": [
        "k-NN",
        "sur-apprentissage",
        "hyperparamètres",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2024-q010",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Comment le lissage par noyau diffère-t-il du k-NN standard ?",
      "choices": [
        "Il ne prend en compte que le voisin le plus proche.",
        "Il utilise une fonction de perte pour optimiser k.",
        "Il pondère les voisins selon leur distance.",
        "Il nécessite des données étiquetées de manière continue."
      ],
      "answer": [
        2
      ],
      "explanation": "Le lissage par noyau diffère du k-NN standard en attribuant un poids à chaque voisin en fonction de sa distance, plutôt que de considérer simplement les k plus proches voisins avec le même poids.",
      "tags": [
        "k-NN",
        "lissage par noyau",
        "pondération",
        "apprentissage supervisé"
      ],
      "id_gen": [
        "qcm001_2025-10-06"
      ]
    },
    {
      "id": "2024-q011",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Le classifieur Bayésien naïf repose sur quelle hypothèse ?",
      "choices": [
        "Toutes les caractéristiques sont dépendantes les unes des autres.",
        "Les caractéristiques sont indépendantes les unes des autres dans chaque classe.",
        "Les données suivent une distribution normale.",
        "Le nombre de caractéristiques est plus important que le nombre d’observations."
      ],
      "answer": [
        1
      ],
      "explanation": "Le classifieur Bayésien naïf repose sur l’hypothèse d’indépendance conditionnelle des variables explicatives, données la classe. Cela simplifie considérablement le calcul des probabilités.",
      "tags": [
        "classifieur bayésien naïf",
        "indépendance conditionnelle",
        "probabilités",
        "apprentissage supervisé"
      ],
      "id_gen": [
        "fixed5_2025-10-06_095834_001"
      ]
    },
    {
      "id": "2024-q012",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "En quoi l’analyse discriminante linéaire Bayésienne (ADL) diffère-t-elle du classifieur bayésien naïf en termes d’hypothèses sur les données ?",
      "choices": [
        "L’ADL ne suppose aucune distribution spécifique des données, contrairement au classifieur bayésien naïf.",
        "L’ADL suppose que les données de chaque classe proviennent d’une distribution gaussienne avec des matrices de covariance identiques, tandis que le classifieur bayésien naïf suppose l’indépendance des caractéristiques.",
        "Le classifieur bayésien naïf est une forme spécifique de l’ADL.",
        "L’ADL et le classifieur bayésien naïf font tous deux l’hypothèse que les caractéristiques sont indépendantes."
      ],
      "answer": [
        1
      ],
      "explanation": "L’ADL repose sur l’hypothèse que les données de chaque classe suivent une distribution gaussienne avec des matrices de covariance identiques, tandis que le classifieur bayésien naïf repose sur l’hypothèse d’indépendance conditionnelle des variables explicatives.",
      "tags": [
        "analyse discriminante linéaire",
        "bayésien naïf",
        "hypothèses",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2024-q013",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Quel est l’objectif principal de l’analyse discriminante Bayésienne ?",
      "choices": [
        "Classifier les données en se basant sur des probabilités a priori.",
        "Trouver une frontière linéaire ou quadratique qui sépare au mieux les classes.",
        "Réduire la dimensionnalité des données.",
        "Estimer la densité de chaque classe dans l’espace des caractéristiques."
      ],
      "answer": [
        1
      ],
      "explanation": "L’analyse discriminante bayésienne (linéaire ou quadratique) a pour objectif principal de déterminer une frontière de décision qui sépare au mieux les classes dans l’espace des caractéristiques.",
      "tags": [
        "analyse discriminante",
        "classification",
        "apprentissage supervisé",
        "frontière de décision"
      ]
    },
    {
      "id": "2024-q014",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Quelle est la différence entre l'analyse discriminante linéaire (ADL) et l'analyse discriminante quadratique (ADQ) ?",
      "choices": [
        "L'ADL est utilisée pour les problèmes de régression, tandis que l'ADQ est utilisée pour la classification.",
        "L'ADL suppose que les données suivent une distribution normale, mais pas l'ADQ.",
        "L'ADL suppose que toutes les classes ont la même matrice de covariance, contrairement à l'ADQ.",
        "L'ADQ est moins sensible aux valeurs aberrantes que l'ADL."
      ],
      "answer": [
        2
      ],
      "explanation": "La principale différence entre ADL et ADQ est que l’ADL suppose que toutes les classes partagent la même matrice de covariance, ce qui conduit à des frontières linéaires, tandis que l’ADQ autorise des matrices de covariance différentes par classe, ce qui donne des frontières quadratiques.",
      "tags": [
        "analyse discriminante",
        "ADL",
        "ADQ",
        "classification",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2024-q015",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Qu'est-ce qu'un arbre de décision CART ?",
      "choices": [
        "Un modèle d’apprentissage supervisé pouvant être utilisé pour des tâches de classification et de régression.",
        "Une méthode de clustering utilisée exclusivement pour les données catégorielles.",
        "Une méthode d’estimation de densité constante par morceaux.",
        "Une technique de réduction de dimensionalité."
      ],
      "answer": [
        0
      ],
      "explanation": "Les arbres de décision CART (Classification And Regression Trees) sont des modèles d’apprentissage supervisé capables de traiter à la fois des tâches de classification et de régression, en partitionnant l’espace des données en sous-régions homogènes.",
      "tags": [
        "arbres de décision",
        "CART",
        "classification",
        "régression",
        "apprentissage supervisé"
      ],
      "id_gen": [
        "fixed5_2025-10-06_095822_001"
      ]
    },
    {
      "id": "2024-q016",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Quel est l’avantage principal des forêts aléatoires par rapport aux arbres de décision uniques ?",
      "choices": [
        "Elles nécessitent moins de temps pour l’entraînement.",
        "Elles réduisent le risque de sur-apprentissage en combinant plusieurs arbres.",
        "Elles produisent des modèles plus simples et plus interprétables.",
        "Elles fonctionnent mieux avec des ensembles de données de petite taille."
      ],
      "answer": [
        1
      ],
      "explanation": "Les forêts aléatoires (Random Forests) réduisent le risque de surapprentissage en agrégeant les prédictions de plusieurs arbres construits sur des échantillons bootstrapés et des sous-ensembles de variables. Cela améliore la robustesse et la généralisation par rapport à un arbre de décision unique.",
      "tags": [
        "forêts aléatoires",
        "arbres de décision",
        "surapprentissage",
        "bagging",
        "apprentissage supervisé"
      ],
      "id_gen": [
        "qcm001_2025-10-06"
      ]
    },
    {
      "id": "2024-q017",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Dans les forêts aléatoires, le caractère « aléatoire » est introduit :",
      "choices": [
        "En utilisant un sous-ensemble aléatoire des caractéristiques à chaque division.",
        "En bootstrapant les données d’entraînement.",
        "En initialisant les arbres au hasard.",
        "En utilisant à la fois un sous-ensemble des caractéristiques à chaque division et le bootstrap des données d’entraînement."
      ],
      "answer": [
        3
      ],
      "explanation": "Dans les forêts aléatoires, l’aléatoire provient de deux sources : le bootstrap des données d’entraînement (bagging) et la sélection aléatoire d’un sous-ensemble de variables à chaque division des arbres. Cela permet de réduire la corrélation entre les arbres et d’améliorer la performance globale.",
      "tags": [
        "forêts aléatoires",
        "bagging",
        "bootstrap",
        "sélection aléatoire de variables",
        "apprentissage supervisé"
      ]
    },
    {
      "id": "2024-q018",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Que représente un 'faux positif' dans une matrice de confusion ?",
      "choices": [
        "Une instance positive correctement identifiée.",
        "Une instance négative correctement identifiée.",
        "Une instance négative incorrectement classée comme positive.",
        "Une instance positive incorrectement classée comme négative."
      ],
      "answer": [
        2
      ],
      "explanation": "Un faux positif (FP) correspond à une instance négative qui a été prédite à tort comme positive par le modèle. Par exemple, un email non-spam classé comme spam.",
      "tags": [
        "matrice de confusion",
        "faux positif",
        "évaluation",
        "classification"
      ]
    },
    {
      "id": "2024-q019",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Si un modèle de classification a une spécificité élevée mais une sensibilité faible, quel est le problème potentiel ?",
      "choices": [
        "Le modèle identifie correctement la majorité des instances positives.",
        "Le modèle manque de nombreuses instances positives, mais identifie bien les instances négatives.",
        "Le modèle est trop complexe et sur-ajusté aux données.",
        "Le modèle est trop simple et sous-ajusté aux données."
      ],
      "answer": [
        1
      ],
      "explanation": "Une spécificité élevée signifie que le modèle détecte bien les instances négatives (peu de faux positifs). Une sensibilité faible indique qu'il échoue à identifier de nombreuses instances positives (beaucoup de faux négatifs).",
      "tags": [
        "sensibilité",
        "spécificité",
        "évaluation",
        "classification"
      ]
    },
    {
      "id": "2024-q020",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Qu'est-ce que la courbe ROC illustre dans le contexte de l'Apprentissage supervisé de classification ?",
      "choices": [
        "La relation entre le taux de vrais positifs et le nombre total de positifs.",
        "La performance du modèle à tous les seuils de classification en montrant la relation entre le taux de vrais positifs et le taux de faux positifs.",
        "La précision du modèle à différents niveaux de seuil de probabilité.",
        "La capacité du modèle à éviter le sur-apprentissage."
      ],
      "answer": [
        1
      ],
      "explanation": "La courbe ROC (Receiver Operating Characteristic) montre la performance d’un modèle en traçant le taux de vrais positifs (sensibilité) en fonction du taux de faux positifs à différents seuils de classification.",
      "tags": [
        "ROC",
        "classification",
        "évaluation",
        "sensibilité",
        "faux positifs"
      ]
    },
    {
      "id": "2024-q018b",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Que représente un 'faux négatif' dans une matrice de confusion ?",
      "choices": [
        "Une instance positive correctement identifiée.",
        "Une instance négative correctement identifiée.",
        "Une instance négative incorrectement classée comme positive.",
        "Une instance positive incorrectement classée comme négative."
      ],
      "answer": [
        3
      ],
      "explanation": "Un faux négatif (FN) correspond à une instance positive que le modèle a classée à tort comme négative. Par exemple, un email spam classé comme non-spam.",
      "tags": [
        "matrice de confusion",
        "faux négatif",
        "évaluation",
        "classification"
      ],
      "id_gen": [
        "qcm001_2025-10-06"
      ]
    },
    {
      "id": "2024-q018c",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Que représente un 'vrai positif' dans une matrice de confusion ?",
      "choices": [
        "Une instance positive correctement identifiée.",
        "Une instance négative correctement identifiée.",
        "Une instance négative incorrectement classée comme positive.",
        "Une instance positive incorrectement classée comme négative."
      ],
      "answer": [
        0
      ],
      "explanation": "Un vrai positif (VP) correspond à une instance positive que le modèle a correctement classée comme positive. Par exemple, un email spam bien identifié comme spam.",
      "tags": [
        "matrice de confusion",
        "vrai positif",
        "évaluation",
        "classification"
      ]
    },
    {
      "id": "2024-q018d",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Que représente un 'vrai négatif' dans une matrice de confusion ?",
      "choices": [
        "Une instance positive correctement identifiée.",
        "Une instance négative correctement identifiée.",
        "Une instance négative incorrectement classée comme positive.",
        "Une instance positive incorrectement classée comme négative."
      ],
      "answer": [
        1
      ],
      "explanation": "Un vrai négatif (VN) correspond à une instance négative que le modèle a correctement classée comme négative. Par exemple, un email non-spam bien identifié comme non-spam.",
      "tags": [
        "matrice de confusion",
        "vrai négatif",
        "évaluation",
        "classification"
      ]
    },
    {
      "id": "2024-q019b",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Si un modèle de classification a une sensibilité élevée mais une spécificité faible, quel est le problème potentiel ?",
      "choices": [
        "Le modèle identifie correctement la majorité des instances négatives.",
        "Le modèle identifie bien les instances positives, mais classe à tort de nombreuses instances négatives comme positives.",
        "Le modèle est trop complexe et sur-ajusté aux données.",
        "Le modèle est trop simple et sous-ajusté aux données."
      ],
      "answer": [
        1
      ],
      "explanation": "Une sensibilité élevée signifie que le modèle détecte bien les instances positives (peu de faux négatifs). Une spécificité faible indique qu'il échoue à identifier correctement les instances négatives (beaucoup de faux positifs).",
      "tags": [
        "sensibilité",
        "spécificité",
        "faux positifs",
        "classification",
        "évaluation"
      ],
      "id_gen": [
        "fixed5_2025-10-06_095834_001"
      ]
    },
    {
      "id": "2024-q019c",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Si un modèle de classification a à la fois une sensibilité faible et une spécificité faible, quel est le problème principal ?",
      "choices": [
        "Le modèle identifie correctement la majorité des instances positives et négatives.",
        "Le modèle échoue à détecter correctement à la fois les instances positives et les instances négatives.",
        "Le modèle est sur-ajusté aux données d'entraînement.",
        "Le modèle est un classifieur parfait."
      ],
      "answer": [
        1
      ],
      "explanation": "Faible sensibilité = beaucoup de faux négatifs ; faible spécificité = beaucoup de faux positifs. Le modèle ne discrimine donc pas bien entre les classes.",
      "tags": [
        "sensibilité",
        "spécificité",
        "erreurs",
        "classification"
      ],
      "id_gen": [
        "fixed5_2025-10-06_095834_001"
      ]
    },
    {
      "id": "2024-q019d",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Si un modèle de classification a à la fois une sensibilité élevée et une spécificité élevée, que peut-on en conclure ?",
      "choices": [
        "Le modèle détecte correctement la majorité des instances positives et négatives.",
        "Le modèle échoue à détecter les instances positives.",
        "Le modèle produit beaucoup de faux positifs.",
        "Le modèle est sous-ajusté."
      ],
      "answer": [
        0
      ],
      "explanation": "Une sensibilité élevée signifie peu de faux négatifs et une spécificité élevée signifie peu de faux positifs. Le modèle est donc performant et bien équilibré.",
      "tags": [
        "sensibilité",
        "spécificité",
        "évaluation",
        "classification"
      ]
    },
    {
      "id": "2024-bonus-q021",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Si un modèle de classification a une sensibilité faible, quel est le problème principal ?",
      "choices": [
        "Le modèle identifie correctement la majorité des instances positives.",
        "Le modèle échoue à détecter un grand nombre d’instances positives (beaucoup de faux négatifs).",
        "Le modèle identifie mal les instances négatives (beaucoup de faux positifs).",
        "Le modèle est sur-ajusté aux données d’entraînement."
      ],
      "answer": [
        1
      ],
      "explanation": "Une sensibilité faible signifie que le modèle manque de nombreuses instances positives, produisant ainsi beaucoup de faux négatifs.",
      "tags": [
        "sensibilité faible",
        "faux négatifs",
        "classification"
      ]
    },
    {
      "id": "2024-bonus-q022",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Si un modèle de classification a une sensibilité élevée, que peut-on en conclure ?",
      "choices": [
        "Le modèle détecte correctement la majorité des instances positives.",
        "Le modèle échoue à détecter de nombreuses instances positives.",
        "Le modèle identifie correctement toutes les instances négatives.",
        "Le modèle produit beaucoup de faux positifs."
      ],
      "answer": [
        0
      ],
      "explanation": "Une sensibilité élevée signifie que le modèle détecte correctement la plupart des instances positives, donc peu de faux négatifs.",
      "tags": [
        "sensibilité élevée",
        "positifs détectés",
        "classification"
      ],
      "id_gen": [
        "fixed5_2025-10-06_095822_001"
      ]
    },
    {
      "id": "2024-bonus-q023",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Si un modèle de classification a une spécificité faible, quel est le problème principal ?",
      "choices": [
        "Le modèle identifie correctement la majorité des instances négatives.",
        "Le modèle échoue à identifier correctement de nombreuses instances négatives (beaucoup de faux positifs).",
        "Le modèle manque beaucoup d’instances positives.",
        "Le modèle ne généralise pas bien sur de nouvelles données."
      ],
      "answer": [
        1
      ],
      "explanation": "Une spécificité faible signifie que le modèle classe à tort de nombreuses instances négatives comme positives, produisant beaucoup de faux positifs.",
      "tags": [
        "spécificité faible",
        "faux positifs",
        "classification"
      ]
    },
    {
      "id": "2024-bonus-q024",
      "qcm": "Partiel-2024",
      "theme": "Apprentissage supervisé",
      "question": "Si un modèle de classification a une spécificité élevée, que peut-on en conclure ?",
      "choices": [
        "Le modèle identifie correctement la majorité des instances négatives.",
        "Le modèle échoue à identifier les instances négatives.",
        "Le modèle manque la majorité des instances positives.",
        "Le modèle est sur-ajusté aux données d’entraînement."
      ],
      "answer": [
        0
      ],
      "explanation": "Une spécificité élevée signifie que le modèle identifie correctement la plupart des instances négatives, donc peu de faux positifs.",
      "tags": [
        "spécificité élevée",
        "négatifs détectés",
        "classification"
      ]
    }
  ]
}
